# 人工质量检查清单

## 用途

这个清单用于人工检查 AI 完成的测试代码质量。每完成一个任务后，按照这个清单逐项检查。

---

## Task 完成检查清单

### ✅ 基础检查（必须全部通过）

- [ ] **1. 所有测试通过**
  ```bash
  pytest tests/ -x
  # 预期: 所有测试通过，0 失败
  ```

- [ ] **2. 代码格式正确**
  ```bash
  python scripts/quality_check.py <new_test_file>
  # 预期: 分数 >= 80
  ```

- [ ] **3. 覆盖率达标**
  ```bash
  pytest <new_test_file> --cov=src/flowby/<module> --cov-report=term
  # 预期: 达到任务目标覆盖率
  ```

- [ ] **4. 验证脚本通过**
  ```bash
  python scripts/verify_tests.py
  # 预期: 所有检查通过
  ```

- [ ] **5. 没有修改业务代码**
  ```bash
  git diff src/
  # 预期: 没有输出（src/ 目录未修改）
  ```

---

## 📋 详细代码审查

### A. 测试结构（每项 0-2 分，满分 10 分）

**评分标准**:
- 0 分：不符合
- 1 分：部分符合
- 2 分：完全符合

#### A1. 文件组织
- [ ] 文件位置正确（unit/integration/e2e）
- [ ] 文件命名规范（test_*.py）
- [ ] 一个文件只测试一个模块/功能

**评分**: ___/2

#### A2. 类和方法组织
- [ ] 使用测试类组织相关测试（class Test*）
- [ ] 测试方法命名清晰（test_<function>_<scenario>_<expected>）
- [ ] 逻辑分组合理

**评分**: ___/2

#### A3. Fixture 使用
- [ ] 合理使用 fixture 减少重复
- [ ] Fixture 命名清晰
- [ ] Fixture 作用域正确（function/class/module）

**评分**: ___/2

#### A4. 测试独立性
- [ ] 每个测试独立运行
- [ ] 测试之间没有依赖
- [ ] 没有共享可变状态

**评分**: ___/2

#### A5. 测试覆盖度
- [ ] 覆盖正常情况（Happy Path）
- [ ] 覆盖边界情况（Edge Cases）
- [ ] 覆盖错误情况（Error Cases）

**评分**: ___/2

**小计 A**: ___/10

---

### B. 测试质量（每项 0-2 分，满分 10 分）

#### B1. 断言质量
- [ ] 每个测试至少 1 个断言
- [ ] 断言具体明确
- [ ] 重要断言有错误消息

**评分**: ___/2

示例：
```python
# ✅ 好的断言
assert result.status_code == 200, f"Expected 200, got {result.status_code}"
assert len(items) == 3
assert "error" not in response

# ❌ 差的断言
assert result  # 太模糊
assert True    # 无意义
```

#### B2. 测试可读性
- [ ] 测试意图清晰
- [ ] 使用 Arrange-Act-Assert 模式
- [ ] 代码简洁易懂

**评分**: ___/2

示例：
```python
# ✅ 好的测试
def test_add_user_success(self):
    # Arrange
    user_data = {"name": "Alice", "email": "alice@example.com"}

    # Act
    result = self.service.add_user(user_data)

    # Assert
    assert result.success is True
    assert result.user_id is not None
```

#### B3. Mock/Stub 使用
- [ ] 合理使用 mock 隔离外部依赖
- [ ] Mock 不过度
- [ ] Mock 验证准确

**评分**: ___/2

#### B4. 参数化测试
- [ ] 合理使用 @pytest.mark.parametrize
- [ ] 减少重复代码
- [ ] 测试用例全面

**评分**: ___/2

#### B5. 错误处理测试
- [ ] 使用 pytest.raises 测试异常
- [ ] 验证异常类型和消息
- [ ] 覆盖各种错误场景

**评分**: ___/2

**小计 B**: ___/10

---

### C. 文档和注释（每项 0-2 分，满分 6 分）

#### C1. 文件文档
- [ ] 文件有文档字符串
- [ ] 说明测试内容和目的
- [ ] 包含参考信息（如果需要）

**评分**: ___/2

示例：
```python
"""
Runner 集成测试

测试 ScriptRunner 的完整执行流程，包括：
- 脚本加载和执行
- 错误处理
- 超时处理
- 诊断信息收集

参考: src/flowby/runner.py
"""
```

#### C2. 类文档
- [ ] 每个测试类有文档字符串
- [ ] 说明测试范围
- [ ] 清晰明了

**评分**: ___/2

#### C3. 测试方法文档
- [ ] 关键测试有文档字符串或注释
- [ ] 说明测试场景
- [ ] 使用表情符号标识（✅❌⚠️）

**评分**: ___/2

**小计 C**: ___/6

---

### D. 代码风格（每项 0-2 分，满分 4 分）

#### D1. 代码格式
- [ ] 符合 Black 格式化标准
- [ ] 行长度 <= 100
- [ ] 缩进一致

**评分**: ___/2

#### D2. 代码风格
- [ ] 符合 Flake8 规范
- [ ] 无未使用的导入
- [ ] 无未使用的变量

**评分**: ___/2

**小计 D**: ___/4

---

## 📊 总体评分

| 类别 | 得分 | 满分 |
|------|------|------|
| A. 测试结构 | ___  | 10   |
| B. 测试质量 | ___  | 10   |
| C. 文档注释 | ___  | 6    |
| D. 代码风格 | ___  | 4    |
| **总计**    | ___  | **30** |

**百分比**: ___% (总分/30 × 100)

---

## 🎯 评级标准

| 分数 | 评级 | 说明 |
|------|------|------|
| 27-30 (90%+) | 🌟 优秀 | 质量极高，可以直接提交 |
| 24-26 (80%+) | ✅ 良好 | 质量合格，稍作调整后提交 |
| 21-23 (70%+) | ⚠️ 及格 | 需要改进，修改后再审查 |
| < 21 (< 70%) | ❌ 不合格 | 质量不达标，需要重写 |

---

## 🔍 常见问题检查

### 问题 1: 测试不够全面

**检查点**:
- [ ] 只测试了 Happy Path，没有测试错误情况
- [ ] 缺少边界情况测试
- [ ] 覆盖率未达标

**建议**:
- 添加错误场景测试
- 添加边界值测试（0、负数、空值、None 等）
- 查看覆盖率报告找到未覆盖的代码

---

### 问题 2: 重复代码过多

**检查点**:
- [ ] 多个测试有相同的 setup 代码
- [ ] 重复的断言逻辑
- [ ] 相似的测试数据

**建议**:
- 提取 fixture
- 使用参数化测试
- 创建辅助函数

---

### 问题 3: Mock 使用不当

**检查点**:
- [ ] 过度 mock（不应该 mock 的也 mock 了）
- [ ] Mock 不够（外部依赖没有隔离）
- [ ] Mock 验证不准确

**建议**:
- 只 mock 外部依赖（网络、文件系统、数据库）
- 不要 mock 被测试的模块
- 使用 assert_called_with 验证 mock 调用

---

### 问题 4: 测试脆弱

**检查点**:
- [ ] 依赖测试执行顺序
- [ ] 依赖外部资源（网络、文件）
- [ ] 使用固定时间或随机值

**建议**:
- 确保测试独立
- Mock 外部依赖
- 使用固定的测试数据

---

### 问题 5: 文档缺失

**检查点**:
- [ ] 没有文件文档
- [ ] 没有类文档
- [ ] 复杂测试没有注释

**建议**:
- 添加文档字符串
- 说明测试目的和场景
- 重要断言添加注释

---

## ✍️ 审查反馈模板

```markdown
## Task <task_id> 审查反馈

### 总体评分: <score>/30 (<percentage>%)

### 通过项 ✅
- <列出通过的检查项>

### 需要改进 ⚠️
- <列出需要改进的地方，按优先级排序>

### 具体问题
1. **问题描述**: <具体问题>
   - **位置**: <文件:行号>
   - **建议**: <改进建议>

2. ...

### 下一步
- [ ] 修复以上问题
- [ ] 重新运行质量检查
- [ ] 提交修改后的代码
```

---

## 📝 审查记录

| Task ID | 审查日期 | 评分 | 状态 | 备注 |
|---------|----------|------|------|------|
| 1.1     | YYYY-MM-DD | __/30 | ✅/⚠️/❌ |      |
| 1.2     | YYYY-MM-DD | __/30 | ✅/⚠️/❌ |      |
| ...     |            |       |      |      |

---

## 🚀 快速检查命令

```bash
# 1. 运行所有测试
pytest tests/ -x

# 2. 质量自动检查
python scripts/quality_check.py <test_file>

# 3. 覆盖率检查
pytest <test_file> --cov=src/flowby/<module> --cov-report=term

# 4. 代码风格
black --check <test_file>
flake8 <test_file>

# 5. 查看进度
python scripts/task_tracker.py status
```

---

**使用此清单确保每个任务的质量！**
